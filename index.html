<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="仓储物流场景下多类物品遥操作灵巧抓取"/>
  <meta property="og:url" content="https://github.com/Z-mingyu/Hospital/"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <title>基于遥操作的智慧病房护理系统</title>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/icon2.png">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="static/js/audioPlayer.js" defer></script>
</head>

<body>

  
<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://evm7.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://evm7.github.io/Self-AWare/">
            Self-AWare
          </a>
          <a class="navbar-item" href="https://evm7.github.io/I-CTRL/">
            I-CTRL
          </a>
          <a class="navbar-item" href="https://evm7.github.io/ECHO/">
            ECHO
          </a>
          <a class="navbar-item" href="https://evm7.github.io/HOI4ABOT_page/">
            HOI4ABOT
          </a>
           <a class="navbar-item" href="https://evm7.github.io/UNIMASKM-page/">
            UNIMASK-M
          </a>
          <a class="navbar-item" href="https://evm7.github.io/icvae-page/">
            IntentionCVAE
          </a>
          <a class="navbar-item" href="https://evm7.github.io/HOIGaze-page/">
            HOIGaze
          </a>
            <a class="navbar-item" href="https://evm7.github.io/2CHTR-page/">
            2CHTR
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->

<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">仓储物流场景下多类物品遥操作灵巧抓取</h1>
          <div class="is-size-3 publication-authors">
            2024.03-2024.12
          </div>
        </div>
    </div>
  </div>

</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
<!--           <div class="is-size-5 publication-authors">
            <span class="author-block">Mingyu Zhang<sup>1</sup> </span>
	    <span class="author-block">Qing Gao*<sup>1</sup> </span>
	    <span class="author-block">Yuanchuan Lai<sup>1</sup> </span>
	    <span class="author-block">Ye Zhang<sup>1</sup> </span>
	    <span class="author-block">Tao Chang<sup>2</sup> </span>
	    <span class="author-block">Yulan Guo<sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sun Yat-sen University  <sup>2</sup>National University of Defense Technology</span> 
            <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span>
          </div> -->
          


<!--           <div class="column has-text-centered">
            <div class="publication-links"> -->
<!--               <span class="link-block">
                <a href="https://arxiv.org/abs/2309.05310" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
 -->
              
              <!-- PDF Link. -->
<!--               <span class="link-block">
               <a href="https://ieeexplore.ieee.org/document/10375150" target="_blank"
                class="external-link button is-normal is-rounded">
                 <span class="icon">
                   <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
<!--                 </span> -->
              <!-- </span> -->
              <!-- Colab Link. -->
<!--              <span class="link-block">-->
<!--                <a href="ADD HERE THE CODE" target="_blank"-->
<!--                class="external-link button is-normal is-rounded">-->
<!--                <span class="icon">-->
<!--                  <i class="fab fa-github"></i>-->
<!--                </span>-->
<!--                <span>Code</span>-->
<!--              </a>-->
<!--             </span>-->

<!--              <span class="link-block">-->
<!--                <a href="ADD HERE REPLICATE IF NEEDED" target="_blank"-->
<!--                class="external-link button is-normal is-rounded">-->
<!--                <span class="icon">-->
<!--                  <i class="fas fa-rocket"></i>-->
<!--                </span>-->
<!--                <span>Demo</span>-->
<!--              </a>-->
<!--              </span>-->
              <!-- </span> -->
              <!-- Colab Link. -->
		    <!-- Play/Pause button and audio -->
<!-- 		    <span class="link-block">
		      <span class="audio-player" style="display: inline-block; vertical-align: middle;">
			<button id="audio-control-button" onclick="toggleAudio()" class="button is-normal is-rounded">
			  <span class="icon">
			    <i id="play-icon" class="fas fa-play"></i>
			  </span>
			  <span id="play-text">Podcast</span>
			</button>
			<audio id="audio-file" src="static/audio/PodCastAudio.wav" type="audio/wav" style="display: none;"></audio>
		  </span>
	    </span> -->
<!-- 	  </div> -->

		 <!-- Hidden Playback Controls + Disclaimer -->
<!-- 	  <div id="audio-controls" style="display: none; margin-top: 15px;">
	    <div>
	      <input id="seek-bar" type="range" min="0" value="0" step="1" style="width: 100%;">
	      <span id="time-remaining">0:00</span> / <span id="duration">0:00</span>
	    </div>
	    
	    <!-- Disclaimer -->
<!-- 	    <div class="disclaimer" style="margin-top: 10px;">
  <p><strong>Disclaimer:</strong> This audio was generated by AI <a href="https://notebooklm.google/" target="_blank">NotebookLM</a> and might contain false or misleading information about the paper. Please refer to the original paper for accurate details.</p>

	    </div>
	  </div> -->

	  <!-- Toggle Visibility Icon -->
<!-- 	  <div id="toggle-visibility-icon" style="display: none; text-align: right; margin-top: 5px;">
	    <i id="visibility-icon" class="fas fa-eye" style="cursor: pointer;" onclick="toggleControls()"></i>
	  </div> -->
	</div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<section class="hero is-small">
  <!~~ <div class="hero-body"> ~~>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!~~ <div id="results-carousel" class="carousel results-carousel"> ~~>
      <div class="container">
      <div class="item">
      <div class="column is-centered has-text-centered">
        <img src="static/figures/teaser.png" alt="UNIMASKM"/>
      </div>

    </div>
  </div>
 <!~~  </div> ~~>
  </div>
  </div>
 <!~~  </div> ~~>
</section>
 -->

  <section class="hero is-small">
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="container">
        <div class="item">
          <p style="margin-bottom: 30px">
 
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/videos/overview.mp4"
          type="video/mp4">
        </video>
        </p>
        </div>
    </div>
  </div>
  </div>
  </div>
</section>
    
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">简介</h2>
        <div class="content has-text-justified">
          <p>
            本系统旨在提升病房护理的智能化和便捷性，特别适用于需要远程照护的医疗场景。系统由一张配备滑轨的病床、安装在滑轨上的机械臂（配备灵巧手）以及两个摄像头组成，实现远程操作下的精准护理。当病人需要获取物品时，操作人员可通过远程控制系统完成任务。首先，机械臂利用摄像头进行全局环境感知，环视病房寻找目标物品，并估计其大致位置。随后，机械臂自动移动至物品附近，确保抓取位置的精准性。在操作环节，远程操作者通过视觉遥操作系统精确控制机械臂抓取目标物品。成功抓取后，机械臂将物品稳妥地递送至病人手中，实现安全、精准、高效的护理支持。该系统可有效减少护理人员的工作负担，提高病房护理的自动化水平，同时为行动不便或长期卧床的病人提供更加便捷的人性化服务。
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
	
<section class="hero is-small">
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="container">
        <div class="item">
          <p style="margin-bottom: 30px">
 
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/videos/overview.mp4"
          type="video/mp4">
        </video>
        </p>
        </div>
    </div>
  </div>
  </div>
  </div>
</section>
    
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">简介</h2>
        <div class="content has-text-justified">
          <p>
          本系统旨在提升病房护理的智能化和便捷性，特别适用于需要远程照护的医疗场景。系统由一张配备滑轨的病床、安装在滑轨上的机械臂（配备灵巧手）以及两个摄像头组成，实现远程操作下的精准护理。当病人需要获取物品时，操作人员可通过远程控制系统完成任务。首先，机械臂利用摄像头进行全局环境感知，环视病房寻找目标物品，并估计其大致位置。随后，机械臂自动移动至物品附近，确保抓取位置的精准性。在操作环节，远程操作者通过视觉遥操作系统精确控制机械臂抓取目标物品。成功抓取后，机械臂将物品稳妥地递送至病人手中，实现安全、精准、高效的护理支持。该系统可有效减少护理人员的工作负担，提高病房护理的自动化水平，同时为行动不便或长期卧床的病人提供更加便捷的人性化服务。
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
	
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/overview.png" alt="Motivation of our model"/>
      </div>    
  </div>
</div>
</div>
</section> -->




<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
         <h2 class="title is-3">How does it work?</h2> 
        <div class="content has-text-justified">
          <p>
Our human-to-robot motion retargeting connects robot control with diverse source modalities, such as a text description, an RGB video, or key poses. Our approach can encode human skeletons into a shared latent space between humans and robots, and subsequently decode these latent variables into the robot’s joint space, enabling direct robot control. Additionally, our approach facilitates the generation of smooth robot motions between human key poses (represented as green and blue dots) through interpolation within the latent space (indicated by the orange dots).
          </p>
        <div class="columns is-centered has-text-centered">
            <div class="item">
          <p style="margin-bottom: 30px"> -->
<!--
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/MDM-page.mp4"
          type="video/mp4">
        </video>
 -->
<!-- <br><br>
        </p>
        </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section> -->

    
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div class="column is-centered has-text-centered">
        <img src="static/figures/modeloverview.jpg" alt="Architecture of our ImitationNet"/>
      </div>    
  </div>
</div>
</div>
</section>
 -->

<!--       <section class="section hero is-light">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Human Motion Retargeting From Videos</h2>
          <p>

            We estimate the human pose from RGB images using an off-the-shelf pose estimator and we feed our ImitationNet model with the predicted human pose. Our model can control the real TiaGo robot in real-time thanks to its light-weight design with a high-accuracy in the retargeting.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>  -->

    
<!--   <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          
      <div class="column is-centered has-text-centered">
        <p><b> “A human and TiaGo are moving among obstacles”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/s0_moving.mp4" type="video/mp4">
                </video>
      </div>
      <div class="column is-centered has-text-centered">
        <p><b> “A human and TiaGo are moving among obstacles”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/s0_moving2.mp4" type="video/mp4">
                </video>
      </div>
      <div class="column is-centered has-text-centered">
        <p><b> “A human and TiaGo are moving among obstacles”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/s2_moving.mp4" type="video/mp4">
                </video>
      </div>
        <div class="column is-centered has-text-centered">
        <p><b> “A human is performing random movements, which TiaGo imitates.”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/random.mp4" type="video/mp4">
                </video>
      </div>
          </div>
      </div>
    </div>
  </section> -->


<!--    <section class="section hero is-light">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Human Motion Retargeting From Text commands</h2>
          <p>

            We use off-the-shelf text-to-motion models to generate a human motion from textual commands, which we then feed to our ImitationNet model. Our model allows therefore the control of the real TiaGo robot from text commands, which facilitates the deployment of natural human-like movements to robots just using text and without any experts demonstrations or robot data.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>  -->

    
<!--   <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          
      <div class="column is-centered has-text-centered">
        <p><b> “A man touches his head with his right arm”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/text2motion/A man touches his head with his right arm (x4).mp4" type="video/mp4">
                </video>
      </div>
      <div class="column is-centered has-text-centered">
        <p><b> “A person is dancing by moving the arms”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/text2motion/A person is dancing by moving the arms (x4).mp4" type="video/mp4">
                </video>
      </div>
      <div class="column is-centered has-text-centered">
        <p><b> “A person is performing a handshake”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/text2motion/A person is performing a hanshake (x4).mp4" type="video/mp4">
                </video>
      </div>
      <div class="column is-centered has-text-centered">
        <p><b> “A person waves with his two hands.”</b></p>
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                  <source src="static/figures/videos/text2motion/A person waves with his two hands (x4).mp4" type="video/mp4">
                </video>
      </div>
          </div>
      </div>
    </div>
  </section> -->

<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Human Motion Retgareting with different robots from textual commands</h2>
          <p>
          To showcase the effectiveness of our approach in retargeting more complex robots, we showcase the Nao, Atlas, and JVRC humanoid robots in simulation imitating any human motion provided. Our framework can learn this retargeting with only 40 minutes of training and only using the robot URDF, without any robot annotated data.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>  -->

<!--     <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          
      <div class="column is-centered has-text-centered">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/figures/videos/robots_simulation/002627_2.mp4" type="video/mp4">
              </video>
      </div>
      <div class="column is-centered has-text-centered">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/figures/videos/robots_simulation/006861.mp4" type="video/mp4">
              </video>
      </div>
        </div>
      </div>
    </div>
  </section> -->


<!--      <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Human Motion Retargeting From Key Poses</h2>
          <p>
      Thanks to our training contrastive learning approach, ImitationNet builts a tractable latent space where similar poses are pushed together while dissimilar are pushed apart. Our model is then able to generate movements between key poses by uniquely interpolating the representation space of two given poses in the latent space.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>  -->

    
<!--   <section class="hero is-small">
    <div class="hero-body">
      <div class="container" style="display: flex; flex-wrap: wrap;">         
        <div class="column is-centered has-text-centered">
          <p><b> “From both hands in the floor to the arm span”</b></p>
                  <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/figures/videos/interpolation/down2open.mp4" type="video/mp4">
                  </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> “From arm span to placing the left arm to the floor”</b></p>
                  <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/figures/videos/interpolation/open2onehandspan.mp4" type="video/mp4">
                  </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> “Changing the arm which is closer to the floor”</b></p>
                  <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/figures/videos/interpolation/onehand2otherhand.mp4" type="video/mp4">
                  </video>
        </div>
        <div class="column is-centered has-text-centered">
          <p><b> “From arms on the upper position to bottom position”</b></p>
                  <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/figures/videos/interpolation/up2down.mp4" type="video/mp4">
                  </video>
        </div>
      </div>
    </div>
    
  </section> -->


<!--   <section class="section hero is-light">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison with the baseline</h2>
          <p>
        We compare our ImitationNet (TiaGo robot on the left of the simulation) with the previous baseline model (located on the right). Our results shows the smooth and accuracy of the pose retargeting, which outperforms previous state-of-the-art.         </p>
        </div>
      </div>
    </div>

  </div>
</section>  -->


<!--       <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          
      <div class="column is-centered has-text-centered">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/figures/videos/baselines/baseline1.mp4" type="video/mp4">
              </video>
      </div>
      <div class="column is-centered has-text-centered">
              <video poster="" id="tree" autoplay controls muted loop height="100%">
                <source src="static/figures/videos/baselines/baseline2.mp4" type="video/mp4">
              </video>
      </div>
        </div>
      </div>
    </div>
  </section> -->
    
    
<!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@INPROCEEDINGS{10375150,
  author={Mingyu Zhang, Qing Gao1, Yuanchuan Lai, Ye Zhang, Tao Chang, Yulan Guo},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={3D Whole-body Pose Estimation Using Graph High-Resolution Network for Humanoid Robot Teleoperation}, 
  year={2025},
  volume={},
  number={}
</code></pre>
    </div>
</section> -->




<!-- <footer class="footer"> -->
 <!--  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
      href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
      <i class="fas fa-file-pdf"></i>
    </a>
    <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
      <i class="fab fa-github"></i>
    </a>
  </div> -->
<!--   <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer> -->

  </body>
  </html>
